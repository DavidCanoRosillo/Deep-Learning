{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pylab inline\n!pip install natsort\n\nimport torch\nimport torchvision\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom zipfile import ZipFile\nfrom natsort import natsorted\nfrom PIL import Image\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\ntorch.manual_seed(1)\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:01:08.928405Z","iopub.execute_input":"2022-03-24T08:01:08.928855Z","iopub.status.idle":"2022-03-24T08:01:20.557626Z","shell.execute_reply.started":"2022-03-24T08:01:08.928778Z","shell.execute_reply":"2022-03-24T08:01:20.556796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class gray2image(torch.utils.data.Dataset):\n    def __init__(self, gray_dir, color_dir, transform):\n        self.gray_dir = gray_dir\n        self.color_dir = color_dir\n        self.transform = transform\n        gray_imgs, color_imgs = os.listdir(gray_dir), os.listdir(color_dir)\n        self.total_gray = natsorted(gray_imgs)\n        self.total_color = natsorted(color_imgs)\n\n    def __len__(self):\n        return len(self.total_gray)\n    \n    def __getitem__(self, idx):\n        img_loc1 = os.path.join(self.gray_dir, self.total_gray[idx])\n        img_loc2 = os.path.join(self.color_dir, self.total_color[idx])\n        image1 = Image.open(img_loc1).convert(\"RGB\")\n        image2 = Image.open(img_loc2).convert(\"RGB\")\n        \n        image1, image2 = self.transform(image1), self.transform(image2)\n        return image1, image2","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:04:08.987076Z","iopub.execute_input":"2022-03-24T08:04:08.987708Z","iopub.status.idle":"2022-03-24T08:04:08.998997Z","shell.execute_reply.started":"2022-03-24T08:04:08.987666Z","shell.execute_reply":"2022-03-24T08:04:08.998252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((256, 256)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\nBS = 1\nds = gray2image('../input/landscape-image-colorization/landscape Images/gray', '../input/landscape-image-colorization/landscape Images/color', transform=std_transform)\nimages_loader = torch.utils.data.DataLoader(ds, batch_size=BS, shuffle = True, drop_last = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T09:32:39.749896Z","iopub.execute_input":"2022-03-24T09:32:39.750175Z","iopub.status.idle":"2022-03-24T09:32:39.89029Z","shell.execute_reply.started":"2022-03-24T09:32:39.750144Z","shell.execute_reply":"2022-03-24T09:32:39.889503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def concat_img(imgs):\n    figsize(16,16)\n    figure()\n    imgs = (imgs + 1) / 2\n    imgs = imgs.movedim((0, 1, 2, 3), (0, 3, 1, 2)).detach().cpu().numpy() \n    axs = imshow(np.concatenate(imgs.tolist(), axis=1))\n    plt.axis('off')\n    plt.show()\n    \ndef print_img(content, style, output):\n    printable = torch.cat((content.cpu(), style.cpu(), output.cpu()), 0)\n    concat_img((printable).detach().cpu())\n    \ngray, color = next(iter(images_loader))\nprint(\"Gray vs color\")\nconcat_img(torch.cat((gray[:4], color[:4]), 0))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:04:30.615168Z","iopub.execute_input":"2022-03-24T08:04:30.615439Z","iopub.status.idle":"2022-03-24T08:04:31.474576Z","shell.execute_reply.started":"2022-03-24T08:04:30.61541Z","shell.execute_reply":"2022-03-24T08:04:31.471367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Generator(torch.nn.Module):\n    def __init__(self, d):\n        def block_down(in_c, out_c, kernel, stride, padding, p, batchnorm=True):\n            if (not batchnorm):\n                return [torch.nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False),\n                    torch.nn.LeakyReLU(0.2),\n                    torch.nn.Dropout(p),\n                    ] # Batchnorm and Dropout regardless train or test\n            return [torch.nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False),\n                    torch.nn.BatchNorm2d(out_c),\n                    torch.nn.LeakyReLU(0.2),\n                    torch.nn.Dropout(p),\n                    ] # Batchnorm and Dropout regardless train or test\n        \n        def block_up(in_c, out_c, kernel, stride, padding, p, last=False):\n            if (last):\n                return [torch.nn.ConvTranspose2d(in_c, out_c, kernel, stride, padding, bias=False),\n                        torch.nn.BatchNorm2d(out_c),\n                        torch.nn.Tanh(),\n                        ] # Batchnorm and Dropout regardless train or test\n            return [torch.nn.ConvTranspose2d(in_c, out_c, kernel, stride, padding, bias=False),\n                    torch.nn.BatchNorm2d(out_c),\n                    torch.nn.ReLU(0.2),\n                    torch.nn.Dropout(p),\n                   ]\n\n        super(Generator, self).__init__()\n        self.down = torch.nn.Sequential(\n            *block_down(3, d, 4, 2, 1, 0, batchnorm=False), #0\n            *block_down(d, d * 2, 4, 2, 1, 0.5, batchnorm=False), #1\n            *block_down(d * 2, d * 4, 4, 2, 1, 0.5), #2\n            *block_down(d * 4, d * 8, 4, 2, 1, 0.5), #3\n            *block_down(d * 8, d * 8, 4, 2, 1, 0.5), #4\n            # ------\n            #*block_down(d * 8, d * 8, 4, 2, 1, 0), #5\n            #*block_down(d * 8, d * 8, 4, 2, 1, 0), #6\n            #*block_down(d * 8, d * 8, 4, 2, 1, 0), #7\n        )\n        \n        self.intermediate = torch.nn.Sequential(\n            *block_down(d * 8, d * 8, 4, 2, 1, 0.5),\n            *block_up(d * 8, d * 8, 4, 2, 1, 0.5),\n        )\n        \n        self.up = torch.nn.Sequential(\n            #*block_up(d * 8, d * 8, 4, 2, 1, 0), # 7\n            #*block_up(d * 8 * 2, d * 8, 4, 2, 1, 0), # 6\n            #*block_up(d * 8 * 2, d * 8, 4, 2, 1, 0), # 5\n            *block_up(d * 8 * 2, d * 8, 4, 2, 1, 0.5), # 4\n            *block_up(d * 8 * 2, d * 4, 4, 2, 1, 0.5), # 3 \n            *block_up(d * 4 * 2, d * 2, 4, 2, 1, 0), # 2\n            *block_up(d * 2 * 2, d, 4, 2, 1, 0), # 1\n            #*block_up(d * 2, d, 4, 2, 1, 0), # 0\n        )\n        self.last = torch.nn.Sequential(\n            *block_up(d, 3, 4, 2, 1, 0, last=True)\n        )\n    def forward(self, x):\n        outputs_down = []\n        i = 0\n        for layer in self.down:\n            x = layer(x)\n            if isinstance(layer, torch.nn.LeakyReLU):\n                outputs_down.append(x)\n        \n        x = self.intermediate(x)\n\n        for layer in self.up:\n            if isinstance(layer, torch.nn.ConvTranspose2d):\n                x = layer(torch.cat((x, outputs_down[len(outputs_down) - 1 - i]), 1))\n                i += 1\n            else:\n                x = layer(x)\n        \n        x = self.last(x)\n        \n        return x\n\nG = Generator(64).cuda()\nG(gray.cuda()).shape","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:04:37.976414Z","iopub.execute_input":"2022-03-24T08:04:37.976678Z","iopub.status.idle":"2022-03-24T08:04:45.80295Z","shell.execute_reply.started":"2022-03-24T08:04:37.97665Z","shell.execute_reply":"2022-03-24T08:04:45.802149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n    def __init__(self, d):\n        super(Discriminator, self).__init__()\n        def block_conv(in_c, out_c, kernel, stride, padding, batchnorm=True):\n            if(batchnorm):\n                return [torch.nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False),\n                        torch.nn.BatchNorm2d(out_c),\n                        torch.nn.LeakyReLU(0.2),\n                        ]\n            return [torch.nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False),\n                   torch.nn.LeakyReLU(0.2)]\n        \n        self.convos = torch.nn.Sequential(\n            *block_conv(6, d, 4, 2, 1, batchnorm=False),\n            *block_conv(d, d * 2, 4, 2, 1),\n            #*block_conv(d * 2, d * 4, 4, 2, 1),\n            #*block_conv(d * 4, d * 8, 4, 1, 1),\n            torch.nn.Conv2d(d * 2, 1, 4, 1, 1),\n            torch.nn.Sigmoid(),\n        )\n    def forward(self, x, y):\n        #y = y + torch.randn_like(y) * 0.1\n        tomonkey = torch.cat((x, y), 1)\n        tomonkey = self.convos(tomonkey)\n        return tomonkey\n\nD = Discriminator(64).cuda()\nprint(gray.shape)\nprint(color.shape)\nD(gray.cuda(), color.cuda()).shape\n#d_loss = BinaryCrossEntropy(D([y_hat, y]), [0, 1])\n#_loss = BinaryCrossEntropy(D[y_hat], [1]) + alpha * torch.mean(||y - y_hat||1)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:04:45.804642Z","iopub.execute_input":"2022-03-24T08:04:45.805037Z","iopub.status.idle":"2022-03-24T08:04:45.830913Z","shell.execute_reply.started":"2022-03-24T08:04:45.804999Z","shell.execute_reply":"2022-03-24T08:04:45.830052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 100\nLR = 2e-4\n\nG = Generator(64).cuda()\nD = Discriminator(64).cuda()\n\ng_lr = LR\nd_lr = LR\n\ng_optim = torch.optim.Adam(G.parameters(), lr=g_lr, betas = (0.5, 0.9))\nd_optim = torch.optim.Adam(D.parameters(), lr=d_lr, betas = (0.5, 0.9))\n\nPATH = '../input/models-pretrained-landscapes/landscapes_v1_g'\ncheckpoint = torch.load(PATH)\nG.load_state_dict(checkpoint['model_state_dict'])\ng_optim.load_state_dict(checkpoint['optimizer_state_dict'])\niters = checkpoint['iters']\n\nPATH = '../input/models-pretrained-landscapes/landscapes_v1_d'\ncheckpoint = torch.load(PATH)\nD.load_state_dict(checkpoint['model_state_dict'])\nd_optim.load_state_dict(checkpoint['optimizer_state_dict'])\niters = checkpoint['iters']","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:11:40.939345Z","iopub.execute_input":"2022-03-24T08:11:40.940033Z","iopub.status.idle":"2022-03-24T08:11:44.572859Z","shell.execute_reply.started":"2022-03-24T08:11:40.939996Z","shell.execute_reply":"2022-03-24T08:11:44.572138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(inputs, targets):\n    BCE = torch.nn.BCELoss().cuda()\n    return BCE(inputs, targets)\n\ndef generator_loss(d_fake_predictions, generated, real, alpha):\n    BCE = torch.nn.BCELoss().cuda()\n    L1 = torch.nn.L1Loss().cuda()\n    gan_loss = BCE(d_fake_predictions, torch.ones(d_fake_predictions.size()).cuda())\n    # l1 loss measures distance between real and generated image\n    l1_loss = L1(generated, real)\n    return gan_loss + alpha * l1_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:11:48.937106Z","iopub.execute_input":"2022-03-24T08:11:48.937942Z","iopub.status.idle":"2022-03-24T08:11:48.944542Z","shell.execute_reply.started":"2022-03-24T08:11:48.937893Z","shell.execute_reply":"2022-03-24T08:11:48.943705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iters = 0\nBS = 1\nepochs = 20\nfor epoch in range(epochs):\n    G.train()\n    D.train()\n    for batch_idx, (gray, color) in enumerate(images_loader):\n        gray, color = gray.cuda(), color.cuda()\n        \n        # Train critic:\n        d_optim.zero_grad()\n        \n        fake = G(gray)\n        d_real = D(gray, color)\n        d_fake = D(gray, fake.detach())\n        predictions = torch.cat((d_real, d_fake), 0)\n        targets = torch.cat((torch.ones(d_real.size()).cuda(), torch.zeros(d_fake.size()).cuda()), 0)\n        \n        d_loss = discriminator_loss(predictions, targets)\n            \n        d_loss.backward()\n        d_optim.step()\n\n        # Train generator:\n        g_optim.zero_grad()\n        \n        fake = G(gray)\n        d_fake = D(gray, fake)\n        g_loss = generator_loss(d_fake, fake, color, alpha)\n\n        g_loss.backward()\n        g_optim.step()\n        if (batch_idx % 500 == 0):\n            print('Epoch {} batch {} Discriminator loss: {:.3f} Generator loss: {:.3f}'.format(epoch, batch_idx, d_loss, g_loss))\n        if (batch_idx % 1000 == 0):\n            print_img(gray[:1], fake[:1], color[:1])\n            plt.show()\n        iters += 1","metadata":{"execution":{"iopub.status.busy":"2022-03-24T08:11:49.557435Z","iopub.execute_input":"2022-03-24T08:11:49.557682Z","iopub.status.idle":"2022-03-24T09:23:35.304071Z","shell.execute_reply.started":"2022-03-24T08:11:49.557653Z","shell.execute_reply":"2022-03-24T09:23:35.303265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"G.eval()\nBS = 128\n#images_loader = torch.utils.data.DataLoader(ds, batch_size=BS, shuffle = True, drop_last = True)\n#gray, color = next(iter(images_loader))\n#fake = G(gray.cuda())\nsample = 20\nprint_img(gray[sample - 1:sample], fake[sample - 1:sample], color[sample - 1:sample])\nsample += 1\nprint_img(gray[sample - 1:sample], fake[sample - 1:sample], color[sample - 1:sample])\nsample += 1\nprint_img(gray[sample - 1:sample], fake[sample - 1:sample], color[sample - 1:sample])\nsample += 1\nprint_img(gray[sample - 1:sample], fake[sample - 1:sample], color[sample - 1:sample])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T09:34:29.039914Z","iopub.execute_input":"2022-03-24T09:34:29.04018Z","iopub.status.idle":"2022-03-24T09:34:32.15083Z","shell.execute_reply.started":"2022-03-24T09:34:29.040142Z","shell.execute_reply":"2022-03-24T09:34:32.150067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets test it on some unseen data from google to check if it generalizes\nBS = 4\nds = gray2image('../input/validation-images', '../input/validation-images', transform=std_transform)\nvalidation_loader = torch.utils.data.DataLoader(ds, batch_size=BS, shuffle = True, drop_last = True)\n\ngray, _ = next(iter(validation_loader))\ngray = gray.cuda()\nfake = G(gray)\nsample = 1\nprint(\"This are unseen during training 256 by 256 images colored\")\nconcat_img(torch.cat((gray[sample - 1:sample], fake[sample - 1:sample]), 0))\nsample += 1\nconcat_img(torch.cat((gray[sample - 1:sample], fake[sample - 1:sample]), 0))\nsample += 1\nconcat_img(torch.cat((gray[sample - 1:sample], fake[sample - 1:sample]), 0))\nsample += 1\nconcat_img(torch.cat((gray[sample - 1:sample], fake[sample - 1:sample]), 0))","metadata":{"execution":{"iopub.status.busy":"2022-03-24T09:29:00.625347Z","iopub.execute_input":"2022-03-24T09:29:00.626139Z","iopub.status.idle":"2022-03-24T09:29:03.818107Z","shell.execute_reply.started":"2022-03-24T09:29:00.626094Z","shell.execute_reply":"2022-03-24T09:29:03.817228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_models():\n    torch.save({\n            'epoch': epoch,\n            'model_state_dict': G.state_dict(),\n            'optimizer_state_dict': g_optim.state_dict(),\n            'loss': g_loss,\n            'iters': iters,\n            }, './landscapes_v2_g')\n    torch.save({\n            'epoch': epoch,\n            'model_state_dict': D.state_dict(),\n            'optimizer_state_dict': d_optim.state_dict(),\n            'loss': d_loss,\n            'iters': iters,\n            }, './landscapes_v2_d')\nsave_models()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T09:36:19.186977Z","iopub.execute_input":"2022-03-24T09:36:19.187338Z","iopub.status.idle":"2022-03-24T09:36:19.871969Z","shell.execute_reply.started":"2022-03-24T09:36:19.187299Z","shell.execute_reply":"2022-03-24T09:36:19.87126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}